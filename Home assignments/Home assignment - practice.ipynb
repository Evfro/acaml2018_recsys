{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your task: implement several models and compare them via CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You'll need to implement several models and use standard polara functionality to perform comprehensive evaluation.\n",
    "- You'll use `BookCrossing` dataset for your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models to choose from:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Implement one of the following 3 groups of models:</div>\n",
    "  \n",
    "1:  \n",
    " - simple content-based model (recommend items based on their feature similarity)\n",
    " - folding-in for unbiased matrix factorization (you can reuse the code for MF shared with you previously)\n",
    "\n",
    "2:\n",
    " - simple item-to-item model\n",
    " - biased matrix factorization model + folding-in\n",
    "  \n",
    "3:\n",
    "- folding-in for the LightFM model according to the solution provided here: https://github.com/lyst/lightfm/issues/300.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation for model comparison:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models should be compared via CV experiements with the following two baselines:\n",
    "    - Popularity-based model\n",
    "    - PureSVD (or ScaledSVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">You must pefform a fair hyper-parameter tuning for both your models (using random grid search) and PureSVD (using rank truncation).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one of the test folds for tuning. Evaluation settings:\n",
    "1. Explicit data:\n",
    "    - warm_start = True\n",
    "    - holdout_size = 3\n",
    "    - random_holdout = True\n",
    "    - models' switch_positive = 7\n",
    "    - evaluation metric: Informedness@10\n",
    "2. Implicit data:\n",
    "    - warm_start = True\n",
    "    - holdout_size = 1\n",
    "    - random_holdout = True\n",
    "    - evaluation metric: MRR@10 (use `model.evaluate('ranking')`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide average value of the metric across all 5 folds as well as confidence intervals for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset for experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you will be using another dataset - **BookCrossing**.\n",
    "It can be downloaded from  \n",
    "http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip.\n",
    "\n",
    "You are provided with the function that will do it for you. As it may take quite a long time, it would be probably better to manually download that data and provide path to the local file as a first input argument to the function instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bookcrossing import get_bx_data\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_data, bx_books_meta = get_bx_data('c:/Users/evfro/Downloads/BX-CSV-Dump.zip', get_books=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_books_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the ratings values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the number of unique users and items with respect to explicit and implicit rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Depending on the type of algorithm you've implemented, perform experiments either on implicit or on explicit part of the dataset.  \n",
    "If your algorithm allows, you can run both (not mandatory).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: selecting the implicit part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explicit part of experiments can be set up in a similar way with the same filtering rules applied. Don't forget to replace implicit data with explicit in the code below!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_data = bx_data.query('rating==0').drop('rating', axis=1) # or just bx_data.query('rating>0') for explicit part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of unique entities will be probably too high to fit their embeddings into standard computer's memory. That's why you need to subsample the data.\n",
    "\n",
    "The following rules should be applied:\n",
    "- filter out all entities with only a single preference\n",
    "- filter out users with too many preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does entities with only a single known preference contribute into standard collaborative filtering models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining valied entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of books\n",
    "books_pref_count = implicit_data['isbn'].value_counts()\n",
    "# mark books with more than 1 user preference\n",
    "valid_books = books_pref_count > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the distribution og the number of books per user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(implicit_data.userid.value_counts().value_counts().sort_index().cumsum()\n",
    "              .plot(logy=True, logx=True, title='Cumulative distribution of user profile length'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the number of users with more than 100 books in their preferences present a tiny fraction of the dataset. Let's filter them out as well as users with only a single preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_pref_count = implicit_data['userid'].value_counts()\n",
    "valid_users = (users_pref_count > 1) & (users_pref_count < 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_book_index = valid_books.index[valid_books]\n",
    "valid_user_index = valid_users.index[valid_users]\n",
    "sampled_data = implicit_data.query('isbn in @valid_book_index and userid in @valid_user_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the resulting data sparsity and the number of unique entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it different from the Movielens data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: functions for content-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara.lib.similarity import combine_similarity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to build similarity matrix. It can be achieved with polara's builtin function  `combine_similarity_data`. The input to this function should be a pandas dataframe with index corresponding to items and columns corresponding to different types of features. Each entry of the dafarame should be a list of feature values. Empty features should be represented by empty list. The following code make the necessary modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info = (bx_books_meta.query('isbn in @valid_book_index').set_index('isbn').fillna('')\n",
    "                          .applymap(lambda x: x.split(',') if len(x) else [])\n",
    "                          .reindex(sampled_data.isbn.unique(), fill_value=[])) # avoid missing isbn index in similarity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ways to build similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can mix similarities computed for various features with different weights or simply sum it with uniform weights (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jw = 'jaccard-weighted'\n",
    "jd = 'jaccard'\n",
    "cs = 'cosine'\n",
    "tc = 'tfidf-cosine'\n",
    "\n",
    "sim_type = {'publisher':cs, 'author':cs}\n",
    "item_similarity = combine_similarity_data(meta_info[list(sim_type.keys())], similarity_type=sim_type, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-at-once similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively**, you can build a single matrix of features of all types and compute similarity on top of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara.lib.similarity import get_similarity_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = meta_info.author.combine(meta_info.publisher, lambda x, y: x+y).to_frame('all_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similarity = get_similarity_data(all_features, similarity_type=tc)['all_features']\n",
    "all_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll also need to add the functionality to operate with similarity data into polara's data model. Here's the way to do it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define a new data model with the necessary functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara import RecommenderData\n",
    "from polara.recommender.coldstart.data import FeatureSimilarityMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new class to mix in the similarity data\n",
    "class SimilarityDataModel(FeatureSimilarityMixin, RecommenderData): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how it should be implemented for the implicit data. **You'll need to add `rating` field for explicit data as in the standard data model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = {'userid': None, 'isbn': item_similarity}\n",
    "sim_indices = {'userid': None, 'isbn': meta_info.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = SimilarityDataModel(similarities, sim_indices,\n",
    "                                 sampled_data, 'userid', 'isbn', # rating is omitted for implicit case\n",
    "                                 seed=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.random_holdout = True\n",
    "data_model.holdout_size = 1\n",
    "data_model.warm_start = True\n",
    "data_model.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.item_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">Your content-based model should use this similarity data to find aggregated scores based on known user preferences for all test users.</div>\n",
    "\n",
    "Hint: use the following command to get sparse representation of test data:  \n",
    "`test_matrix, slice_data = self.get_test_matrix(test_data, shape, (start, stop))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara import RecommenderModel\n",
    "\n",
    "class ContentBased(RecommenderModel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ContentBased, self).__init__(*args, **kwargs)\n",
    "        self.method = 'CB'\n",
    "    \n",
    "    def build(self, *args, **kwargs):\n",
    "        # your implementation\n",
    "        \n",
    "    def slice_recommendations(self, test_data, shape, start, stop, test_users=None):\n",
    "        # your implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
