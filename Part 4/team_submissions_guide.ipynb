{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from polara import RecommenderData\n",
    "from polara import get_movielens_data\n",
    "from polara import SVDModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data now is provided externally. The holdout is not shared with you. Your task is to build a model using the `Movielens-10M` dataset (either full or subsampled, it's up to you) and generate recommendations for provided test users. Everything can be done within polara's API, so you only need to configure the `data_model` accordingly. Here's how to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_movielens_data('<path to ml-10m.zip file>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fields(userid='userid', itemid='movieid', feedback='rating')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model = RecommenderData(data, 'userid', 'movieid', 'rating', seed=0)\n",
    "data_model.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the entire ML-10M dataset for training, simply call `prepare_training_only` method, which doesn't perform any data splitiing and only reindexes users and movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Done.\n",
      "There are 10000054 events in the training and 0 events in the holdout.\n"
     ]
    }
   ],
   "source": [
    "data_model.prepare_training_only()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the entire dataframe went into the training part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to specify, which test data should be used by the data model. First of all, download the test data itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv('https://github.com/Evfro/acaml2018_recsys/raw/master/Part%204/team_testset.gz', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(388502, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userid     8671\n",
       "movieid    7381\n",
       "rating       10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testset.shape)\n",
    "testset.apply('nunique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the **test users are not from the ML-10M dataset**, so the `warm_start` scenario should be invoked. There's a special method `set_test_data`, allowing to assign the externally provided test data and to activate the necessary configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.set_test_data(testset=testset, warm_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method will automatically perform all the necessary steps in order to ensure consistency between training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is ready to use the model of your choice as before. Below is an example based on `PureSVD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVDModel(data_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume you've already performed hyper-parameter tuning and verified it with cross-validation. All is needed now is to generate recommendations with your optimally tuned model and submit them to the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVD training time: 3.204495320337614s\n"
     ]
    }
   ],
   "source": [
    "svd.rank = 35\n",
    "svd.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a convenience function, which ensure correct configuration of your model when submitting it. The configuration corresponds to the rules of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_model(model, submission_name):\n",
    "    model.topk = 50 # recommendations will be evaluated in a range from 1 to 50\n",
    "    recs = model.recommendations\n",
    "    # restoring actual movieid indices instead of internal ones\n",
    "    mapping = model.data.index.itemid.set_index('new').old\n",
    "    recs = pd.Series(recs.ravel()).map(mapping).values.reshape(recs.shape)    \n",
    "    # saving the array and submitting it\n",
    "    np.savez(submission_name, recs=recs)\n",
    "    files = {'upload': open(f'{submission_name}.npz','rb')}\n",
    "    url = \"http://recsysvalley.azurewebsites.net/upload\"\n",
    "    r = requests.post(url, files=files)\n",
    "    return r.status_code, r.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 'OK')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_model(svd, 'svd_baseline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
